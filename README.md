# Исследование хештаблиц

## Описание

В данном проекте реализована хештаблица методом цепочек и исследованы следующие ее части:

1. Xеш-функции, чтобы понять, какая из них распределяет наиболее равномерно по хештаблице. 
2. Производительность операции поиска в хештаблице и возможности ее оптимизировать.

Опишем, как устроена хештаблица.

## Описание хештаблицы

Хештаблица написана методом цепочек, в качестве ключа выступает строчка, в качестве значения - булевская переменная. Если строчка есть в хештаблицы, то ее значение - true, как бы подтверждение факта существования этой строчки в хештаблице. Цепочки реализованы с помощью моей реализации [cache-friendly двусвязного списка](https://github.com/d3clane/list), которая использует динамический массив для хранения блоков данных.

Схематичный вид хештаблицы:

![hash table](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/HashTable.png)

На картинке показано, что два входных значения с ключами "emberlizard" и "soggyturtle" на выходе с хеш-функции получают одно и то же значение, а значит попадают в одну ячейку хештаблицы. Здесь используется список, чтобы последовательно сохранить эти значения в одной ячейке - как бы цепочка.

Для исследования используется набор топ [370000 английский слов](https://github.com/dwyl/english-words?tab=readme-ov-file). Load-factor для моей хештаблицы равен $7.52$. Почему так много? Это необходимо, чтобы лучше видеть, насколько равномерно хеш-функции распределяют по хештаблице. Если бы load-factor был оптимальным и подбирался для ускорения работы хеш таблицы(около 0.7), то при исследовании распределения пики загруженности отдельных ячеек были бы не так видны и могло бы показаться, что распределение получается близким к равномерному, хотя на деле это не так. Сам же размер хеш таблицы равен 49157 - это простое число, так как при таком выборе распределение будет более вероятно равномерным. Объясню выбор размера, равным простому числу, подробнее:

Часто данные на выходе с хеш-функции могут иметь какой-то свой паттерн, то есть идти с каким-то шагом или же число элементов кратных какому-то $k$ больше, чем других. Пусть наша хеш-функция получила на вход какие-то данные, а на выходе дала ${k, 2k, 3k, 4k, ...}$ - все данные кратны $k$. Для того, чтобы данные попали в ячейки хештаблицы результаты берутся по модулю $hashTableSize$ - то есть по модулю количества ячеек в хештаблице. Тогда посмотрим, сколько различных ячеек в таком случае сможет заполнить хештаблица, в сколькие она чисто теоретически может положить эти данные. Данные начнут попадать в одни и те же ячейки, когда 

$$k \equiv r \cdot k \pmod{hashTableSize}$$, где $r - 1$ получается равным количеству различных остатков по делению, который можно получить. Решим это уравнение - его можно переписать в виде:

$$k + hashTableSize \cdot \alpha = r \cdot k$$, где $\alpha$ - какое-то целое число. Наименьшее $k$, когда это выполняется - $r \cdot k = LCM(k, hashTableSize)$, то есть $r \cdot k = \frac{k \cdot hashTableSize}{GCD(k, hashTableSize)}$ или $$r = \frac{hashTableSize}{GCD(k, hashTableSize)}$$. 

Получается, что взяв hashTableSize простым числом мы с большей вероятностью получим $GCD(k, hashTableSize) = 1$, то есть сможем заполнить все клетки хештаблицы. 

## Исследование хеш-функций
 
Все хеш-функции имеют сигнатуру вида `uint32_t HashFunc(const char* inString)`, всего было написано 8 различных хеш-функций:

1. [ConstantHash](#Constant-hash)
2. [FirstCharASCIIHash](#First-char-ASCII-hash)
3. [StringLengthHash](#String-length-hash)
4. [SumCharsASCIIHash](#Sum-chars-ASCII-hash)
5. [RolHash](#Rol-hash)
6. [RorHash](#Ror-hash)
7. [MurmurHash](#Murmur-hash)
8. [CRC32Hash](#CRC32-hash)

Несложно увидеть, что некоторые из них заведомо плохие, но все равно необходимы для более полного исследования.

Исследование будет как визуальное, так и формульное - строятся графики, сраниваются, а также считается стандартное отклонение. Стандартное отклонение считается по формуле: 

$$standardDeviation = \sqrt{\frac{\sum\limits_{i = 0}^{n} (x_i - x_{mean})^2}{n}}$$ где $x_i$ - длина i-й цепочки, $x_{mean}$ - средняя длина цепочки, а $n$ - количество таких цепочек. В моем случае $n = 49157$.

### Constant hash

```
uint32_t ConstantHash(const char* inString)
{
    assert(inString);

    return (uint32_t)42;
}
```

Данная хеш-функция всегда возвращает число 42.

Очевидно, что с такой хеш-функцией в хештаблице всегда будет заполняться только одна ячейка и работать будет медленно:

![ConstantHash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/ConstantHash.png). 

В увеличенном масштабе:

![ConstantHashClose](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/ConstantHashClose.png)

Стандартное отклонение - 1669.3.

Здесь проблема в методе хеширования очевидна - заполняется только одна ячейка.

### First char ASCII hash

```
uint32_t FirstCharASCIIHash(const char* inString)
{
    assert(inString);

    return (uint32_t)inString[0];
}
```

Эта хеш-функция возвращает ASCII код первой буквы строки. 

Ожидаемо, распределение должно быть в границах $[97, 122]$, где 97 - ASCII код буквы 'a', 122 - ASCII код буквы 'z'. То есть заполняется очень малое число ячеек. Гистограмма распределения:

![First char ASCII](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/FirstCharASCIIHash.png)

В увеличенном масштабе:

![First char ASCII close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/FirstCharASCIIHashClose.png)

Стандартное отклонение - 403.4.

По гистограмме можно понять, что наиболее часто слова начинаются на буквы 'c', 'p', 's', так как на них максимальные пики загруженности. Наиболее редко на букву 'x'. 

Проблема данного метода хеширования в ограниченности количества использованных ячеек, а также в том, что есть буквы, с которых слова почти не начинаются, а значит эти ячейки почти не будут заполнены.

### String length hash

```
uint32_t StringLengthHash(const char* inString)
{
    assert(inString);

    return (uint32_t)strlen(inString);
}
```

Эта хеш-функция возвращает длину строки.

Средняя длина английского слова - 4.7, считается что самое длинное слово - pneumonoultramicroscopicsilicovolcanoconiosis, длина которого 45. Получается, что на нашем датасете значения будут в границах [1, 45], причем ожидается нормальное распределение, так как фактически слов очень малой и очень большой длины сильно меньше, чем слов средней длины. Проверим на практике:

![string length hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/StringLengthHash.png)

В увеличенном масштабе:

![string length hash close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/StringLengthHashClose.png)

Стандартное отклонение - 525.9.

Проблема такого метода хеширование в сильной ограниченности количества использованных ячеек, а также в нормальном распределении. 

### Sum chars ASCII hash

```
uint32_t SumCharsASCIIHash(const char* inString)
{
    assert(inString);

    uint32_t sum = 0;
    const char* inStringPtr = inString;

    while (*inStringPtr)
    {
        sum += (uint32_t)(*inStringPtr);
        ++inStringPtr;
    }

    return sum;
}
```

Эта хеш-функция суммирует ASCII коды букв строки и возвращает как результат хеширования.

Оценим, какой результат мне может вернуть подобная хеш-функция. Самое длинное слово - 45 букв, буква с самым большим ASCII кодом - 'z' =  122. Тогда результат $\leq 45 * 122 = 5490$. Это, очевидно никогда не достигается (не существует слова 'zzzzzzz....'). При этом в среднем английских слов больше в районе от 4 до 15 букв, то есть значения в районе $'a' * 4 = 388 \leq hashFuncRes \leq 'z' * 15 = 1830$. До этого размер хештаблицы был $49157$, сейчас, специально выбирем размер $389$. Зачем это было сделано - будет понятно позже. 

Полученный график:

![ASCII sum small cap](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHashSmallCap.png)

Стандартное отклонение - 156.5.

Казалось бы - неплохая хеш-функция - заполняет всю область определения, да, есть пики, но если бы load-factor был бы в разы меньше, такого бы не наблюдалось. Получается, если увеличить размер хеш-таблицы получится очень хорошее распредение, так ведь? Проверим.

Вернемся к прошлому размеру хештаблицы. Полученный график:

![ASCII sum](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHash.png)

В увеличенном масштабе:

![ASCII sum close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHashClose.png)

Стандартное отклонение - 63.7.

Видно очень ярко выраженные пики, даже несмотря на то, что размер хеш таблицы увеличился. Ячейки с номером больше 2500 почти не заполнялись - экстраполировать результат не удалось. Сверху уже объяснялась причина такого поведения - это же не случайный набор букв, а полноценные английские слова. Для них есть закономерности в виде средней длины слова, самые часто встречающиеся буквы и тому подобное - отсюда и вытекает подобное распределение.

### Rol hash

```
uint32_t RolHash(const char* inString)
{
    assert(inString);

    uint32_t hash = 0;
    const char* inStringPtr = inString;

    while (*inStringPtr)
    {
        hash = Rol(hash) ^ (uint32_t)(*inStringPtr);
        ++inStringPtr;
    }

    return hash;
}

static inline uint32_t Rol(uint32_t dWord)
{
    return ((dWord << 1) | (dWord >> (sizeof(dWord) * 8 - 1)));
}
```

Эта хеш-функция пересчитывает hash по формуле $hash(n) = ROL(hash(n - 1)) \oplus str[n]$, пробегаясь по всем буквам в строке, где str - строчка, str[n] - $n$-я буква строки, ROL - битовая операция rotate left. Изначально hash(0) = 0, нумерация с единицы. $\oplus$ - операция XOR. 

Помимо хеширования интересует следующий момент - на ассемблере существует инструкция `rol`, сможет ли компилятор увидеть это и заменить вызов моей функции `Rol` просто инструкцией. Проверим это в godbolt'e. 

![No opt rol](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/NoOptRol.png)

Даже без оптимизаций компилятор смог заметить, что это инструкция rol и заменить ее! Правда, все равно оставил вызов моей функции Rol. А теперь с оптимизацией -O1:

![Opt rol](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/OptRol.png)

Компилятор полностью избавился от вызова функции Rol и заменил его инструкцией rol. C флагами -O2, -O3 никаких оптимизаций с инструкцией rol больше не происходит. 

Теперь график распределения:

![Rol hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/RolHash.png)

Стандартное отклонение - 8.3.

Заметно, что как-то чередуются размеры списков - подряд идет много сильно заполненных списков, затем много мало заполненных. При этом при больших значениях хеша распределение идет уже равномерное.

### Ror hash

```
uint32_t RorHash(const char* inString)
{
    assert(inString);

    uint32_t hash = 0;
    const char* inStringPtr = inString;

    while (*inStringPtr)
    {
        hash = Ror(hash) ^ (uint32_t)(*inStringPtr);
        ++inStringPtr;
    }

    return hash;
}

static inline uint32_t Ror(uint32_t dWord)
{
    return ((dWord >> 1) | (dWord << (sizeof(dWord) * 8 - 1)));
}
```

Эта хеш функция аналогична RolHash, только $hash(n) = ROR(hash(n - 1)) \oplus str[n]$. ROR - битовая операция rotate right.

Результаты в godbolt абсолютно такие же, компилятор замечает, что это инструкция ror. График заполненности:

![Ror hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/RorHash.png)

Стандартное отклонение - 18.0

Распределение хуже, чем для RolHash, так как есть очень высокие пики. С чем это может быть связано?Средний размер слова в районе 5 - 16 символов. Получается около 5-16 rotate right моего hash, то есть очень сильно заполняются верхние 5 - 16 бит моего хеша. А потом этот хеш берется по модулю $49157$ и все эти биты становятся резко малозначимыми, и, как итог, очень много хешей совпадают по модулю.

### Murmur hash

```
uint32_t MurMurHash(const char* inString)
{
    assert(inString);

    static const uint32_t seed = time(NULL);

    const uint32_t c1 = 0x5bd1e995; 
    const uint32_t c2 = 24;

    size_t length = strlen(inString);
    uint32_t hash = seed ^ (uint32_t)length;

    uint32_t word = 0;

    const char* inStringPtr = inString;
    while (length >= 4)
    {
        word  = (uint32_t)inStringPtr[0];
        word |= (uint32_t)inStringPtr[1] <<  8;
        word |= (uint32_t)inStringPtr[2] << 16;
        word |= (uint32_t)inStringPtr[3] << 24;

        word *= c1;
        word ^= word >> c2;
        word *= c1;

        hash *= c1;
        hash ^= word;

        inStringPtr += 4;
        length -= 4;
    }

    assert(length < 4);

    switch (length)
    { 
        case 3:
            hash ^= (uint32_t)inStringPtr[2] << 16;
            // fall through
        case 2:
            hash ^= (uint32_t)inStringPtr[1] << 8;
            // fall through
        case 1:
            hash ^= (uint32_t)inStringPtr[0];
            hash *= c1;
            break;
        default:
            break;
    };

    hash ^= hash >> 13;
    hash *= c1;
    hash ^= hash >> 15;

    return hash;
}
```

Кратко объяснить идею этой хеш-функции не получится, поэтому лучше прочитать страницу [википедии](https://en.wikipedia.org/wiki/MurmurHash).

Распределение на графике:

![MurMurHash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/MurMurHash.png)

Из-за особенностей масштаба на графике не видно, что на самом деле существуют списки с не очень большими размерами. Догадаться о их существовании легко - если судить по графику, то получится, что load-factor не соответствует заявленному (по графику он кажется явно больше 7.5). Как раз для таких случаев и нужен подсчет стандартного отклонения, чтобы дополнительно формульно оценить и сопоставить с визуальными результатами. MurMurHash в увеличенном масштабе:

![MurMurHash close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/MurMurHashClose.png)

Стандартное отклонение - 2.74. 

Видно, что распределение получается достаточно равномерным. 

### CRC32 hash

```
uint32_t CRC32Hash(const char* inString)
{
    unsigned int crc = 0xFFFFFFFF, mask = 0;

    const char* inStringPtr = inString;
    while (*inStringPtr)
    {
        crc = crc ^ (unsigned int)(*inStringPtr);

        for (int j = 7; j >= 0; j--)
        {
            mask = -(crc & 1);
            crc = (crc >> 1) ^ (0xEDB88320 & mask);
        }

        ++inStringPtr;
    }

    return (uint32_t)~crc;
}
```

Аналогично Murmur hash, чтобы понять идею, лучше обратиться к [википедии](https://en.wikipedia.org/wiki/Cyclic_redundancy_check).

Распределение на графике:

![CRC32 hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CRC32Hash.png)

Здесь тоже из-за особенностей масштаба не видно, что на самом деле есть и списки с не очень большими размерами. В увеличенном масштабе получится:

![CRC32 hash close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CRC32HashClose.png)

Стандартное отклонение - 2.75.

Это тоже хорошо распределяющая хеш-функция.

### Промежуточный вывод

Сводная таблица стандартных отклонений для различных хеш-функций:

|                       |Стандартное отклонение |
|---                    |---                    |
|Сonstant hash          | 1669.3                |
|First char ASCII hash  | 403.4                 |
|String length hash     | 525.9                 |
|Sum chars ASCII hash   | 63.7                  |
|Ror hash               | 18.0                  |
|Rol hash               | 8.3                   |
|CRC32 hash             | 2.75                  |
|Murmur hash            | 2.74                  |

Очевидно, стоит выбирать между MurMurHash и CRC32 Hash, так как распределение получается наиболее равномерным, при этом особой разницы между распределениями нет - и визуально, и формульно (стандартное отклонение) они максимально похожи. Следующим критерием выбора может служить скорость работы каждой из хеш-функций - они вызываются при операциях вставки / удаления / поиска в хештаблице, то есть достаточно часто. Для своей хештаблицы я выберу CRC32, потому что такой выбор даст мне больший простор для оптимизаций во второй части работы - существуют intrinsic-и, которые реализуют алгоритм хеширования CRC32, а значит есть возможность для ускорения. 

## Оптимизация хештаблицы

Для тестирования времени работы операции поиска в хештаблице используем следующий алгоритм:
1. Все элементы из тестового файла с английскими словами инсертим в хештаблицу, сохраняем их себе в массив, чтобы больше не тратить время на чтение из файла.
2. В цикле 100 раз пробегаются все данные из массива английских слов, для каждого элемента вызывается функция поиска в хештаблице.

Измеряется время, которая тратится непосредственно на 2-ю часть алгоритма - поиск в хештаблице. Время измеряется в тактах процессора с помощью функции, написанной на ассемблере и которая использует инструкцию `rdtsc`. Представления времени в таком виде достаточно, так как для измерения улучшение производительности программы достаточно смотреть во сколько раз стало быстрее работать.

При измерении времени проводится три запуска программы с флагами компилятора `-O3 -mavx2 -D NDEBUG`, а затем среднее время по трем запускам усредняется с помощью метода наименьших квадратов, чтобы исключить внешние влияния от других процессов на компьютере.

Для оптимизаций нужно понимать, что, собственно, надо в первую очередь оптимизировать, то есть необходимо найти узкие места в программе. Для этого будем использовать `valgrind --tool=callgrind`, а результат просматривать с помощью kcachegrind. Данная утилита поможет измерить время работы отдельных частей программы и определить, что необходимо оптимизировать в первую очередь.

Производительность программы будем улучшать тремя способами:
1. Использование intrinsic-ов.
2. Написание кода на встроенном ассемблере.
3. Написание кода в отдельном файле на ассемблере и линковка с моей программой.

Несложно понять, что такие оптимизации не всегда хорошо. Их использование сильно привязывает к конкретной архитектуре, код становится сложнее поддерживать и читать, поэтому надо держать баланс между написанными строчками кодами для оптимизации и полученным выигрышем в производительности. Если выигрыш незначительный, но при этом код кардинально меняется, скорее стоит отказаться от подобной оптимизации, чем применять ее. Для оценки баланса между написанными строчками кода и выигрыше в производительности будем использоваться следующий коэффициент:

$$balance = \frac{\frac{T / T_0}}{NumberOfOptimizingCodeLines} \cdot 1000$$

где $T_0$ - время выполнения программы без оптимизаций, $T$ - время выполнения программы с оптимизациями, $NumberOfOptimizingCodeLines$ - количество строк кода, написанных с помощью intrinsic-ов / ассемблера в ходе оптимизации. 

При применении каждой из оптимизаций будем строить таблицу 

|                     |Абсолютное ускорение |Относительное ускорение|
|---                  |---                  |---                    |
|Наивная реализация   | 1                   |  1                    |
|Оптимизация 1        | $K_1$               | $K_1$                 |
|Оптимизация 2        | $K_2$               | $K_3$                 |

Абсолютное ускорение - во сколько раз быстрее стала работать программа относительно наивной реализации после применения оптимизаций. 

Относительное ускорение - во сколько раз быстрее стала работать программа относительно предыдущей версии с оптимизациями. Для первой оптимизации абсолютное и относительные ускорения одинаковы.

## Запуск без оптимизаций

Для начала померяем время работы наивной реализации программы без каких-либо оптимизаций:

|                     |Запуск 1     |Запуск 2     |Запуск 3     | Среднее по мнк           |
|---                  |---          |---          |---          |---                       |
|Наивная реализация   | 54363679966 | 55726000650 | 54755185012 | $(549 \pm 7) \cdot 10^8$ |

Характерное время одного запуска - около 20 секунд. 

## Поиск узких мест

Используем `valgrind --tool=cachegrind` и посмотрим, насколько оптимизированно мы используем кеш в программе. Результат:

![Cache grind](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CacheGrind.png)

Видно, что мы и так оптимизированно используем кеш и нет особых предпосылок для того, чтобы пытаться что-то еще сильнее улучшить - кардинальных улучшений производительности не получить.

Теперь рассмотрим непосредственно время, потраченное на вызов различных функций. Результат, полученный с помощью valgrind:

![CallGrindNoOpt](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CallGrindNoOpt.png)

Функции отсортированны по значению во второму столбце. Этот столбец отвечает за время, потраченное непосредственно на код самой функции без учета времени, потраченного на функции, вызванные из-под нее. Время выполнение различных частей указывается в процентах от общего времени выполнения. Рассмотрим первые две строчки:

|                           | Процент от общего времени работы |
|---                        |---                               |
| CRC32                     | 41.31                            |
| __strcmp_sse2_unaligned   | 7.82                             |

И первым в списке оказывается CRC32Hash - функция хеширования, времени на нее тратится в разы больше, чем на любую другую функцию, значит ее и стоит оптимизировать первой. 

## CRC32 intrinsic

Вспомним, что существуют ассемблерные инструкции, реализующие CRC32 hash и, соответственно, intrinsic-и для них. Мы будем применять intrinsic `unsigned __int64 _mm_crc32_u64 (unsigned __int64 crc, unsigned __int64 v)`, который принимает на вход int64, то есть способен хешировать 8 байт одновременно. Здесь возникает проблема - а какая длинна у нашего слова - кратна ли она 8? нужен ли мне цикл для того, чтобы знать сколько раз подряд вызывать хеш? Давайте проанализируем наши слова.

Наш датасет состоит из английских слов, а не из случайного набор букв. Можно смело предположить, что слов длины больше 32 почти не бывает, а если такое появляется - можно поддерживать вторую хештаблицу для слов большой длины. В силу того, что таких слов мало(в моем датасете таких вообще нет), такая хештаблица не будет влиять на производительность. То есть будем считать, что все слова дополнены до 32 байт и нужно вызывать функцию хеширования ровно 4 раза. Возникает вопро - а кто должен дополнять слова до 32 байт? Здесь два сценария:

1. Моя хеш-таблица получает слово на вход, дополняет до 32 байт и только потом начинает поиск.
2. При обращении к таблице уже гарантируется, что слова дополнены до 32 байт.

Второй вариант предпочтительнее, так как если ключи невозможно выравнять заранее и программе, использующей хештаблицу, придется каждый раз дополнять слова, то это очевидно работает не хуже, чем первый вариант, так как это эквивалентные действия. Но при этом, если есть возможность заранее выравнять ключи, которые будут представлять собой запросы к хештаблице, то 2-й вариант очевидно будет работать быстрее, так как хештаблице не нужно тратить время на аллокацию дополнительной памяти и копирования туда строчки. 

В своем тестировании программы я заранее дополняю все ключи до 32 байт, поэтому время на это не учитывается в итоговом времени работы. 

Новая реализация CRC32:

```
uint32_t CRC32HashIntrinsic(const char* inString)
{
    uint32_t crc = 0;
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 0));
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 1));
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 2));
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 3));

    return crc;
}
```

Здесь предполагается, что на входные строчки выделено хотя бы 32 байта памяти, чтобы не было обращения не к своей памяти. 

Измерения:

|                     |Запуск 1     |Запуск 2     |Запуск 3     | Среднее по мнк           |
|---                  |---          |---          |---          |---                       |
|Intrinsic CRC32      | 42270152762 | 42905688226 | 40852393806 | $(420 \pm 11) * 10^8$    |

Характерное время работы программы - около 15 секунд.

Выигрыш в производительности:

|                     |Абсолютное ускорение |Относительное ускорение|
|---                  |---                  |---                    |
|Наивная реализация   | 1                   |  1                    |
|Intrinsic CRC32      | $1.31 \pm 0.05$     | $1.31 \pm 0.05$       |

