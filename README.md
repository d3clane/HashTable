# Исследование хештаблиц

## Описание

В данном проекте реализована хештаблица методом цепочек и исследованы следующие ее части:

1. Xеш-функции, чтобы понять, какая из них распределяет наиболее равномерно по хештаблице. 
2. Производительность операции поиска в хештаблице и возможности ее оптимизировать.

Опишем, как устроена хештаблица.

## Описание хештаблицы

Хештаблица написана методом цепочек, в качестве ключа выступает строчка, в качестве значения - булевская переменная. Если строчка есть в хештаблицы, то ее значение - true, как бы подтверждение факта существования этой строчки в хештаблице. Цепочки реализованы с помощью моей реализации [cache-friendly двусвязного списка](https://github.com/d3clane/list), которая использует динамический массив для хранения блоков данных.

Схематичный вид хештаблицы:

![hash table](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/HashTable.png)

На картинке показано, что два входных значения с ключами "emberlizard" и "soggyturtle" на выходе с хеш-функции получают одно и то же значение, а значит попадают в одну ячейку хештаблицы. Здесь используется список, чтобы последовательно сохранить эти значения в одной ячейке - как бы цепочка.

Для исследования используется набор топ [370000 английский слов](https://github.com/dwyl/english-words?tab=readme-ov-file). Load-factor для моей хештаблицы равен $7.52$. Почему так много? Это необходимо, чтобы лучше видеть, насколько равномерно хеш-функции распределяют по хештаблице. Если бы load-factor был оптимальным и подбирался для ускорения работы хеш таблицы(около 0.7), то при исследовании распределения пики загруженности отдельных ячеек были бы не так видны и могло бы показаться, что распределение получается близким к равномерному, хотя на деле это не так. Сам же размер хеш таблицы равен 49157 - это простое число, так как при таком выборе распределение будет более вероятно равномерным. Объясню выбор размера, равным простому числу, подробнее:

Часто данные на выходе с хеш-функции могут иметь какой-то свой паттерн, то есть идти с каким-то шагом или же число элементов кратных какому-то $k$ больше, чем других. Пусть наша хеш-функция получила на вход какие-то данные, а на выходе дала ${k, 2k, 3k, 4k, ...}$ - все данные кратны $k$. Для того, чтобы данные попали в ячейки хештаблицы результаты берутся по модулю $hashTableSize$ - то есть по модулю количества ячеек в хештаблице. Тогда посмотрим, сколько различных ячеек в таком случае сможет заполнить хештаблица, в сколькие она чисто теоретически может положить эти данные. Данные начнут попадать в одни и те же ячейки, когда 

$$k \equiv r \cdot k \pmod{hashTableSize}$$, где $r - 1$ получается равным количеству различных остатков по делению, который можно получить. Решим это уравнение - его можно переписать в виде:

$$k + hashTableSize \cdot \alpha = r \cdot k$$, где $\alpha$ - какое-то целое число. Наименьшее $k$, когда это выполняется - $r \cdot k = LCM(k, hashTableSize)$, то есть $r \cdot k = \frac{k \cdot hashTableSize}{GCD(k, hashTableSize)}$ или $$r = \frac{hashTableSize}{GCD(k, hashTableSize)}$$. 

Получается, что взяв hashTableSize простым числом мы с большей вероятностью получим $GCD(k, hashTableSize) = 1$, то есть сможем заполнить все клетки хештаблицы. 

## Исследование хеш-функций
 
Все хеш-функции имеют сигнатуру вида `uint32_t HashFunc(const char* inString)`, всего было написано 8 различных хеш-функций:

1. [ConstantHash](#Constant-hash)
2. [FirstCharASCIIHash](#First-char-ASCII-hash)
3. [StringLengthHash](#String-length-hash)
4. [SumCharsASCIIHash](#Sum-chars-ASCII-hash)
5. [RolHash](#Rol-hash)
6. [RorHash](#Ror-hash)
7. [MurmurHash](#Murmur-hash)
8. [CRC32Hash](#CRC32-hash)

Несложно увидеть, что некоторые из них заведомо плохие, но все равно необходимы для более полного исследования.

Исследование будет как визуальное, так и формульное - строятся графики, сраниваются, а также считается стандартное отклонение. Стандартное отклонение считается по формуле: 

$$standardDeviation = \sqrt{\frac{\sum\limits_{i = 0}^{n} (x_i - x_{mean})^2}{n}}$$ где $x_i$ - длина i-й цепочки, $x_{mean}$ - средняя длина цепочки, а $n$ - количество таких цепочек. В моем случае $n = 49157$.

### Constant hash

```
uint32_t ConstantHash(const char* inString)
{
    assert(inString);

    return (uint32_t)42;
}
```

Данная хеш-функция всегда возвращает число 42.

Очевидно, что с такой хеш-функцией в хештаблице всегда будет заполняться только одна ячейка и работать будет медленно:

![ConstantHash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/ConstantHash.png). 

В увеличенном масштабе:

![ConstantHashClose](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/ConstantHashClose.png)

Стандартное отклонение - 1669.3.

Здесь проблема в методе хеширования очевидна - заполняется только одна ячейка.

### First char ASCII hash

```
uint32_t FirstCharASCIIHash(const char* inString)
{
    assert(inString);

    return (uint32_t)inString[0];
}
```

Эта хеш-функция возвращает ASCII код первой буквы строки. 

Ожидаемо, распределение должно быть в границах $[97, 122]$, где 97 - ASCII код буквы 'a', 122 - ASCII код буквы 'z'. То есть заполняется очень малое число ячеек. Гистограмма распределения:

![First char ASCII](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/FirstCharASCIIHash.png)

В увеличенном масштабе:

![First char ASCII close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/FirstCharASCIIHashClose.png)

Стандартное отклонение - 403.4.

По гистограмме можно понять, что наиболее часто слова начинаются на буквы 'c', 'p', 's', так как на них максимальные пики загруженности. Наиболее редко на букву 'x'. 

Проблема данного метода хеширования в ограниченности количества использованных ячеек, а также в том, что есть буквы, с которых слова почти не начинаются, а значит эти ячейки почти не будут заполнены.

### String length hash

```
uint32_t StringLengthHash(const char* inString)
{
    assert(inString);

    return (uint32_t)strlen(inString);
}
```

Эта хеш-функция возвращает длину строки.

Средняя длина английского слова - 4.7, считается что самое длинное слово - pneumonoultramicroscopicsilicovolcanoconiosis, длина которого 45. Получается, что на нашем датасете значения будут в границах [1, 45], причем ожидается нормальное распределение, так как фактически слов очень малой и очень большой длины сильно меньше, чем слов средней длины. Проверим на практике:

![string length hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/StringLengthHash.png)

В увеличенном масштабе:

![string length hash close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/StringLengthHashClose.png)

Стандартное отклонение - 525.9.

Проблема такого метода хеширование в сильной ограниченности количества использованных ячеек, а также в нормальном распределении. 

### Sum chars ASCII hash

```
uint32_t SumCharsASCIIHash(const char* inString)
{
    assert(inString);

    uint32_t sum = 0;
    const char* inStringPtr = inString;

    while (*inStringPtr)
    {
        sum += (uint32_t)(*inStringPtr);
        ++inStringPtr;
    }

    return sum;
}
```

Эта хеш-функция суммирует ASCII коды букв строки и возвращает как результат хеширования.

Оценим, какой результат мне может вернуть подобная хеш-функция. Самое длинное слово - 45 букв, буква с самым большим ASCII кодом - 'z' =  122. Тогда результат $\leq 45 \cdot 122 = 5490$. Это, очевидно никогда не достигается (не существует слова 'zzzzzzz....'). При этом в среднем английских слов больше в районе от 4 до 15 букв, то есть значения хеш-функции в районе $a \cdot 4 = 388 \leq hashFuncRes \leq z \cdot 15 = 1830$. До этого размер хештаблицы был $49157$, сейчас, специально выбирем размер $389$. Зачем это было сделано - будет понятно позже. 

Полученный график:

![ASCII sum small cap](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHashSmallCap.png)

Также проверим на другом [датасете](/TestsInput/ListSizesTest/wordsCommon.txt) из 3000 самых популярных английских слов, для них load-factor = 7.7:

![ASCII sum small cap common](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHashSmallCapCommon.png)

Казалось бы - неплохая хеш-функция - в первом случае ее проблема в гигантском load-factor'е, а в случае с топ 3000 самыми популярными английскими словами выглядит вполне неплохо. Получается, если увеличить размер хештаблицы, получится очень хорошее распредение, так ведь? Проверим.

Вернемся к прошлому размеру хештаблицы. Полученный график для датасета из 370к слов:

![ASCII sum](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHash.png)

В увеличенном масштабе:

![ASCII sum close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHashClose.png)

Стандартное отклонение - 63.7.

Для датасета из 3к слов:

![ASCII sum common](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHashCommon.png)

В увеличенном масштабе:

![ASCII sum common close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/SumCharsASCIIHashCommonClose.png)

А пики никуда не исчезли...

Видно очень ярко выраженные пики, даже несмотря на то, что размер хеш таблицы увеличился. Ячейки с номерами больше 2500 почти не заполнялись, а начиная с какого-то номера ни один ключ не попал в эти ячейки - экстраполировать результат не удалось. Сверху уже объяснялась причина такого поведения - это же не случайный набор букв, а полноценные английские слова. Для них есть закономерности в виде средней длины слова, самые часто встречающиеся буквы и тому подобное - отсюда и вытекает подобное распределение.

### Rol hash

```
uint32_t RolHash(const char* inString)
{
    assert(inString);

    uint32_t hash = 0;
    const char* inStringPtr = inString;

    while (*inStringPtr)
    {
        hash = Rol(hash) ^ (uint32_t)(*inStringPtr);
        ++inStringPtr;
    }

    return hash;
}

static inline uint32_t Rol(uint32_t dWord)
{
    return ((dWord << 1) | (dWord >> (sizeof(dWord) * 8 - 1)));
}
```

Эта хеш-функция пересчитывает hash по формуле $hash(n) = ROL(hash(n - 1)) \oplus str[n]$, пробегаясь по всем буквам в строке, где str - строчка, str[n] - $n$-я буква строки, ROL - битовая операция rotate left. Изначально hash(0) = 0, нумерация с единицы. $\oplus$ - операция XOR. 

Помимо хеширования интересует следующий момент - на ассемблере существует инструкция `rol`, сможет ли компилятор увидеть это и заменить вызов моей функции `Rol` просто инструкцией. Проверим это в godbolt'e. 

![No opt rol](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/NoOptRol.png)

Даже без оптимизаций компилятор смог заметить, что это инструкция rol и заменить ее! Правда, все равно оставил вызов моей функции Rol. А теперь с оптимизацией -O1:

![Opt rol](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/OptRol.png)

Компилятор полностью избавился от вызова функции Rol и заменил его инструкцией rol. C флагами -O2, -O3 никаких оптимизаций с инструкцией rol больше не происходит. 

Теперь график распределения:

![Rol hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/RolHash.png)

Стандартное отклонение - 8.3.

Заметно, что как-то чередуются размеры списков - подряд идет много сильно заполненных списков, затем много мало заполненных. При этом при больших значениях хеша распределение идет уже равномерное.

### Ror hash

```
uint32_t RorHash(const char* inString)
{
    assert(inString);

    uint32_t hash = 0;
    const char* inStringPtr = inString;

    while (*inStringPtr)
    {
        hash = Ror(hash) ^ (uint32_t)(*inStringPtr);
        ++inStringPtr;
    }

    return hash;
}

static inline uint32_t Ror(uint32_t dWord)
{
    return ((dWord >> 1) | (dWord << (sizeof(dWord) * 8 - 1)));
}
```

Эта хеш функция аналогична RolHash, только $hash(n) = ROR(hash(n - 1)) \oplus str[n]$. ROR - битовая операция rotate right.

Результаты в godbolt абсолютно такие же, компилятор замечает, что это инструкция ror. График заполненности:

![Ror hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/RorHash.png)

Стандартное отклонение - 18.0

Распределение хуже, чем для RolHash, так как есть очень высокие пики. С чем это может быть связано?Средний размер слова в районе 5 - 16 символов. Получается около 5-16 rotate right моего hash, то есть очень сильно заполняются верхние 5 - 16 бит моего хеша. А потом этот хеш берется по модулю $49157$ и все эти биты становятся резко малозначимыми, и, как итог, очень много хешей совпадают по модулю.

### Murmur hash

```
uint32_t MurMurHash(const char* inString)
{
    assert(inString);

    static const uint32_t seed = time(NULL);

    const uint32_t c1 = 0x5bd1e995; 
    const uint32_t c2 = 24;

    size_t length = strlen(inString);
    uint32_t hash = seed ^ (uint32_t)length;

    uint32_t word = 0;

    const char* inStringPtr = inString;
    while (length >= 4)
    {
        word  = (uint32_t)inStringPtr[0];
        word |= (uint32_t)inStringPtr[1] <<  8;
        word |= (uint32_t)inStringPtr[2] << 16;
        word |= (uint32_t)inStringPtr[3] << 24;

        word *= c1;
        word ^= word >> c2;
        word *= c1;

        hash *= c1;
        hash ^= word;

        inStringPtr += 4;
        length -= 4;
    }

    assert(length < 4);

    switch (length)
    { 
        case 3:
            hash ^= (uint32_t)inStringPtr[2] << 16;
            // fall through
        case 2:
            hash ^= (uint32_t)inStringPtr[1] << 8;
            // fall through
        case 1:
            hash ^= (uint32_t)inStringPtr[0];
            hash *= c1;
            break;
        default:
            break;
    };

    hash ^= hash >> 13;
    hash *= c1;
    hash ^= hash >> 15;

    return hash;
}
```

Кратко объяснить идею этой хеш-функции не получится, поэтому лучше прочитать страницу [википедии](https://en.wikipedia.org/wiki/MurmurHash).

Распределение на графике:

![MurMurHash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/MurMurHash.png)

Из-за особенностей масштаба на графике не видно, что на самом деле существуют списки с не очень большими размерами. Догадаться о их существовании легко - если судить по графику, то получится, что load-factor не соответствует заявленному (по графику он кажется явно больше 7.5). Как раз для таких случаев и нужен подсчет стандартного отклонения, чтобы дополнительно формульно оценить и сопоставить с визуальными результатами. MurMurHash в увеличенном масштабе:

![MurMurHash close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/MurMurHashClose.png)

Стандартное отклонение - 2.74. 

Видно, что распределение получается достаточно равномерным. 

### CRC32 hash

```
uint32_t CRC32Hash(const char* inString)
{
    unsigned int crc = 0xFFFFFFFF, mask = 0;

    const char* inStringPtr = inString;
    while (*inStringPtr)
    {
        crc = crc ^ (unsigned int)(*inStringPtr);

        for (int j = 7; j >= 0; j--)
        {
            mask = -(crc & 1);
            crc = (crc >> 1) ^ (0xEDB88320 & mask);
        }

        ++inStringPtr;
    }

    return (uint32_t)~crc;
}
```

Аналогично Murmur hash, чтобы понять идею, лучше обратиться к [википедии](https://en.wikipedia.org/wiki/Cyclic_redundancy_check).

Распределение на графике:

![CRC32 hash](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CRC32Hash.png)

Здесь тоже из-за особенностей масштаба не видно, что на самом деле есть и списки с не очень большими размерами. В увеличенном масштабе получится:

![CRC32 hash close](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CRC32HashClose.png)

Стандартное отклонение - 2.75.

Это тоже хорошо распределяющая хеш-функция.

### Промежуточный вывод

Сводная таблица стандартных отклонений для различных хеш-функций:

|                       |Стандартное отклонение |
|---                    |---                    |
|Сonstant hash          | 1669.3                |
|First char ASCII hash  | 403.4                 |
|String length hash     | 525.9                 |
|Sum chars ASCII hash   | 63.7                  |
|Ror hash               | 18.0                  |
|Rol hash               | 8.3                   |
|CRC32 hash             | 2.75                  |
|Murmur hash            | 2.74                  |

Очевидно, стоит выбирать между MurMurHash и CRC32 Hash, так как распределение получается наиболее равномерным, при этом особой разницы между распределениями нет - и визуально, и формульно (стандартное отклонение) они максимально похожи. Следующим критерием выбора может служить скорость работы каждой из хеш-функций - они вызываются при операциях вставки / удаления / поиска в хештаблице, то есть достаточно часто. Для своей хештаблицы я выберу CRC32, потому что такой выбор даст мне больший простор для оптимизаций во второй части работы - существуют intrinsic-и, которые реализуют алгоритм хеширования CRC32, а значит есть возможность для ускорения. 

## Оптимизация хештаблицы

Для тестирования времени работы операции поиска в хештаблице используем следующий алгоритм:
1. Все элементы из тестового файла с английскими словами инсертим в хештаблицу, сохраняем их себе в массив, чтобы больше не тратить время на чтение из файла.
2. В цикле 100 раз пробегаются все данные из массива английских слов, для каждого элемента вызывается функция поиска в хештаблице.

Измеряется время, которая тратится непосредственно на 2-ю часть алгоритма - поиск в хештаблице. Время измеряется в тактах процессора с помощью функции, написанной на ассемблере и которая использует инструкцию `rdtsc`. Представления времени в таком виде достаточно, так как для измерения улучшение производительности программы достаточно смотреть во сколько раз стало быстрее работать.

При измерении времени проводится три запуска программы с флагами компилятора `-O3 -mavx2 -D NDEBUG`, а затем среднее время по трем запускам усредняется с помощью метода наименьших квадратов, чтобы исключить внешние влияния от других процессов на компьютере.

Для оптимизаций нужно понимать, что, собственно, надо в первую очередь оптимизировать, то есть необходимо найти узкие места в программе. Для этого будем использовать `valgrind --tool=callgrind`, а результат просматривать с помощью kcachegrind. Данная утилита поможет измерить время работы отдельных частей программы и определить, что необходимо оптимизировать в первую очередь.

Производительность программы будем улучшать тремя способами:
1. Использование intrinsic-ов.
2. Написание кода на встроенном ассемблере.
3. Написание кода в отдельном файле на ассемблере и линковка с моей программой.

Несложно понять, что такие оптимизации не всегда хорошо. Их использование сильно привязывает к конкретной архитектуре, код становится сложнее поддерживать и читать, поэтому надо держать баланс между написанными строчками кодами для оптимизации и полученным выигрышем в производительности. Если выигрыш незначительный, но при этом код кардинально меняется, скорее стоит отказаться от подобной оптимизации, чем применять ее. Для оценки баланса между написанными строчками кода и выигрыше в производительности будем использоваться следующий коэффициент:

$$balance = \frac{\frac{T}{T_0}}{NumberOfOptimizingCodeLines} \cdot 1000$$

где $T_0$ - время выполнения программы без оптимизаций, $T$ - время выполнения программы с оптимизациями, $NumberOfOptimizingCodeLines$ - количество строк кода, написанных с помощью intrinsic-ов / ассемблера в ходе оптимизации. 

При применении каждой из оптимизаций будем строить таблицу 

|                     |Абсолютное ускорение |Относительное ускорение|
|---                  |---                  |---                    |
|Наивная реализация   | 1                   |  1                    |
|Оптимизация 1        | $K_1$               | $K_1$                 |
|Оптимизация 2        | $K_2$               | $K_3$                 |

Абсолютное ускорение - во сколько раз быстрее стала работать программа относительно наивной реализации после применения оптимизаций. 

Относительное ускорение - во сколько раз быстрее стала работать программа относительно предыдущей версии с оптимизациями. Для первой оптимизации абсолютное и относительные ускорения одинаковы.

## Запуск без оптимизаций

Для начала померяем время работы наивной реализации программы без каких-либо оптимизаций:

|                     |Запуск 1     |Запуск 2     |Запуск 3     | Среднее по мнк           |
|---                  |---          |---          |---          |---                       |
|Наивная реализация   | 50843355582 | 50002732758 | 51492446142 | $(508 \pm 8) \cdot 10^8$ |

Характерное время одного запуска - около 20 секунд. 

## Поиск узких мест

Используем `valgrind --tool=cachegrind` и посмотрим, насколько оптимизированно мы используем кеш в программе. Результат:

![Cache grind](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CacheGrind.png)

Видно, что мы и так оптимизированно используем кеш и нет особых предпосылок для того, чтобы пытаться что-то еще сильнее улучшить - кардинальных улучшений производительности не получить. 

Теперь рассмотрим непосредственно время, потраченное на вызов различных функций. Результат, полученный с помощью valgrind:

![CallGrindNoOpt](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CallGrindCRC32Opt.png)

Функции отсортированны по значению во второму столбце. Этот столбец отвечает за время, потраченное непосредственно на код самой функции без учета времени, потраченного на функции, вызванные из-под нее. Время выполнение различных частей указывается в процентах от общего времени выполнения. Рассмотрим первые две строчки:

|                           | Процент от общего времени работы |
|---                        |---                               |
| CRC32                     | 55.01                            |
| __strcmp_sse2_unaligned   | 11.37                             |

И первым в списке оказывается CRC32Hash - функция хеширования, времени на нее тратится в разы больше, чем на любую другую функцию, значит ее и стоит оптимизировать первой. 

## CRC32 intrinsic

Вспомним, что существуют ассемблерные инструкции, реализующие CRC32 hash и, соответственно, intrinsic-и для них. Мы будем применять intrinsic `unsigned __int64 _mm_crc32_u64 (unsigned __int64 crc, unsigned __int64 v)`, который принимает на вход int64, то есть способен хешировать 8 байт одновременно. Здесь возникает проблема - а какая длинна у нашего слова - кратна ли она 8? Нужен ли мне цикл для того, чтобы знать сколько раз подряд вызывать хеш? Давайте проанализируем наши слова.

Наш датасет состоит из английских слов, а не из случайного набора букв. Можно смело предположить, что слов длины больше 32 почти не бывает, а если такое появляется - можно поддерживать вторую хештаблицу для слов большой длины. В силу того, что таких слов мало(в моем датасете таких вообще нет), такая хештаблица не будет влиять на производительность. То есть будем считать, что все слова дополнены до 32 байт и нужно вызывать функцию хеширования ровно 4 раза. Возникает вопрос - а кто должен дополнять слова до 32 байт? Здесь два сценария:

1. Моя хеш-таблица получает слово на вход, дополняет до 32 байт и только потом начинает поиск.
2. При обращении к таблице уже гарантируется, что слова дополнены до 32 байт.

Второй вариант предпочтительнее, так как если ключи невозможно выравнять заранее и программе, использующей хештаблицу, придется каждый раз дополнять слова, то это очевидно работает не хуже, чем первый вариант, так как это эквивалентные действия. Но при этом, если есть возможность заранее выравнять ключи, которые будут представлять собой запросы к хештаблице, то 2-й вариант очевидно будет работать быстрее, так как хештаблице не нужно тратить время на аллокацию дополнительной памяти и копирования туда строчки. 

В своем тестировании программы я заранее дополняю все ключи до 32 байт, поэтому время на это не учитывается в итоговом времени работы. 

Новая реализация CRC32:

```
uint32_t CRC32HashIntrinsic(const char* inString)
{
    uint32_t crc = 0;
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 0));
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 1));
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 2));
    crc = _mm_crc32_u64(crc, *((uint64_t*)inString + 3));

    return crc;
}
```

Здесь предполагается, что на входные строчки выделено хотя бы 32 байта памяти, чтобы не было обращения к не своей памяти. 

Измерения:

|                     |Запуск 1     |Запуск 2     |Запуск 3     | Среднее по мнк           |
|---                  |---          |---          |---          |---                       |
|Intrinsic CRC32      | 28663836850 | 27360564576 | 28704863644 | $(282 \pm 8) \cdot 10^8$     |
                        
Характерное время работы программы - около 13 секунд.

Выигрыш в производительности:

|                     |Абсолютное ускорение |Относительное ускорение|
|---                  |---                  |---                    |
|Наивная реализация   | 1                   |  1                    |
|Intrinsic CRC32      | $1.80 \pm 0.08$     | $1.80 \pm 0.08$       |

## Strcmp на встроенном ассемблере

Снова запустим valgrind:

![CallGrindCRC32Intrinsic](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CallGrindStrCmpOpt.png)

Видно, что теперь узким местом является функция strcmp, которая и так была оптимизирована компилятором с использованием SSE инструкций. 

Опять вспомним, что размер слова не превышает 32 байт. А это идеально вписывается в размер YMM регистра. Представим себе, что наши слова хранятся в двух YMM регистрах. Каждый байт - это ASCII код буквы. Тогда, выгрузив строчки в YMM регистры, можно сравнить их и вернуть результат. Заметим, что существует intrinsic `int _mm256_testc_si256 (__m256i a, __m256i b)`, которая делает `(~a & b)` и ставит CF = 1, если `(~a & b) == 0`. Очевидно что `(~a & b) == 0` тогда и только тогда, когда `a == b`. То есть с помощью этой операции можно быстро сравнить два YMM регистра на равенство. Причем, у инструкции vptest есть версия, которая в качестве второго операнда принимает указатель на память, то есть нет необходимости выгружать второй операнд. К сожалению, на intrinsic-ах такого не реализовано. 

Напишем свою реализацию strcmp с использованием встроенного ассемблера и сделаем ее inline, так как это достаточно маленькая функция, и трата времени на ее вызов может быть значительной. Для начала напишем на intrinsic-ах. Для выгрузки из памяти будем использовать intrinsic, работающий с невыровннными по границе в 32 байта строчками, затем напишем с выровннными и сравним. 

```
bool StrCmp(const char* str1, const char* str2)
{
    __m256i val1 = _mm256_loadu_si256((__m256i*)str1);
    __m256i val2 = _mm256_loadu_si256((__m256i*)str2);

    int mask = _mm256_testc_si256(val1, val2);

    return mask;
}
```

Компилируется в:

```
StrCmp(char const*, char const*):
        vmovdqu ymm0, YMMWORD PTR [rdi]
        vptest  ymm0, YMMWORD PTR [rsi]
        setb    al
        vzeroupper
        ret
```

Здесь сразу можно заметить, что даже несмотря на факт того, что я выгружаю оба операнда из памяти и использую intrinsic, который работает с двумя ymm регистрами, он смог обнаружить, что можно использовать эту же инструкцию, но работающую с операндами `ymm, m256`, а не `ymm, ymm`.

Среди необычного - инструкция vzeroupper. При компиляции с флагом оптимизации `-O1` этой инструкции нет. Погуглив, я нашел упоминания об этом на сайте [intel](https://www.intel.com/content/dam/develop/external/us/en/documents/11mc12-avoiding-2bavx-sse-2btransition-2bpenalties-2brh-2bfinal-809104.pdf), в котором говорится:

> When using Intel® AVX instructions, it is important to know that mixing 256-bit Intel® AVX instructions with legacy (non VEX-encoded) Intel® SSE instructions may result in penalties that could impact performance. 

То есть смешивание AVX и SSE инструкций может привести к тому, что производительность программы может упасть. В силу того, что заранее неизвестно, будут ли использоваться в дальнейшем SSE инструкции, после использования AVX инструкций предлагается использовать `vzeroupper`, чтобы обнулить верхние части YMM регистров, и при использовании SSE инструкций время на сохранение верхних частей не тратилось.

Итак, перепишем на встроенном ассемблере:

```
static inline int AsmStrcmp(const char* str1, const char* str2)
{
   int res = 0;

    __asm__ inline (
        ".intel_syntax noprefix\n\t"
        "vmovdqu ymm0, YMMWORD PTR [%1]\n\t" //read str1
        "vptest ymm0, YMMWORD PTR[%2]\n\t"   // cmp str1 and str2
        "setc %b0\n\t"                       // set carry flag to res
        "vzeroupper\n\t"                     // explained in readme
        ".att_syntax prefix\n\t"
        : "+&r" (res)
        : "r" (str1), "r" (str2)
        : "ymm0", "cc"
    );

    return res;
}
```

Моя реализация `AsmStrcmp` возвращает 1, если строчки совпадают и 0 в другом случае. 

Перед измерениями обращу внимание на баг, с которым я столкнулся в ходе написания `AsmStrcmp`. Обратим внимание на output operands моего asm-кода, а именно `: "+&r" (res)`. До этого у меня использовалось `: "=&r" (res)` и код работал неверно. Почему? В случае '=', я говорю компилятору, чтобы мне нужен res только на запись и меня не интересует, что в нем находится - в этом и проблема. Компилятор, увидев такую информацию, выкинул инициализацию `res = 0`, и по итогу в нем хранился мусор, как следствие функция часто могла вернуть ненулевое значение, так как инструкция `setc %b0%`, заполняет только нижние 8 бит регистра, предоставленного под `res`. 

Итак, перейдем к измерениям:

|                     |Запуск 1     |Запуск 2     |Запуск 3     | Среднее по мнк           |
|---                  |---          |---          |---          |---                       |
|strcmp unaligned     | 21314818430 | 20246098392 | 19284039290 | $(203 \pm 10) \cdot 10^8$    |
                        
Характерное время работы - около 10 секунд.

Теперь перепишем с использованием инструкции, которая требует выравнивания. Соответственно, для выравнивания, будем использовать `aligned_alloc`. 

В данном случае `vmovdqu` меняется на `vmovdqa`.
```
static inline int AsmStrcmp(const char* str1, const char* str2)
{
   int res = 0;

    __asm__ inline (
        ".intel_syntax noprefix\n\t"
        "vmovdqa ymm0, YMMWORD PTR [%1]\n\t" //read str1 aligned
        "vptest ymm0, YMMWORD PTR[%2]\n\t"   // cmp str1 and str2
        "setc %b0\n\t"                       // set carry flag to res
        "vzeroupper\n\t"                     // explained in readme
        ".att_syntax prefix\n\t"
        : "+&r" (res)
        : "r" (str1), "r" (str2)
        : "ymm0", "cc"
    );

    return res;
}
```

При выделении памяти используется `aligned_alloc`, который выравнивает по границе в 32 байта. Для начала выравниваем только ключи, которые хранятся в моей хештаблице - именно они используются в инструкции `vmovdqa`. Перед измерениями я проверил, что без использования `aligned_alloc` моя программа падает с ошибкой, то есть изначально выравнивания по границе в 32 байта нет, а значит тесты имеют смысл.

Измерения:

|                            |Запуск 1     |Запуск 2     |Запуск 3     | Среднее по мнк           |
|---                         |---          |---          |---          |---                       |
|strcmp aligned only keys    | 20497446244 | 21949195036 | 20672952570 | $(210 \pm 8) \cdot 10^8$     |

Теперь выравняем также и ключи, которые мы подаем на вход функции поиска, чтобы найти их в таблице (то есть мы выравним str2 для функции AsmStrcmp). 

Измерения:


|                            |Запуск 1     |Запуск 2     |Запуск 3      | Среднее по мнк           |
|---                         |---          |---          |---           |---                       |
|strcmp aligned only all     | 21011997628 | 22021311548 | 20672952570  | $(219 \pm 9) \cdot 10^8$ |

Время не улучшилось, а, возможно даже ухудшилось (значения лежат в пределах погрешности). При этом требование выравнивания сильно влияет на стабильность программы, так как если его не окажется - вылетит ошибка. Также выравнивание требует дополнительных строчек кода, которые показывают, что необходимо выравнивание, что ухудшает читабельность кода. Откажемся от использования инструкции, требующей выравнивания.

Выигрыш в производительности:

|                     |Абсолютное ускорение |Относительное ускорение|
|---                  |---                  |---                    |
|Наивная реализация   | 1                   |  1                    |
|Intrinsic CRC32      | $1.80 \pm 0.08$     | $1.80 \pm 0.08$       |
|Strcmp inlined asm   | $2.50 \pm 0.16$     | $1.39 \pm 0.11$       |

Выигрыш все еще удовлетворительный, оптимизацию оставляем.

## Поиск элемента в списке

Снова запустим valgrind:

![list opt](https://github.com/d3clane/HashTable/blob/main/ReadmeAssets/imgs/CallGrindListOpt.png)

Видно, что теперь самая "тяжелая" функция - поиск элемента в списке по ключу. Вот ее код:

```
HtListErrors HtListFindElemByKey(HtListType* list, const char* key, size_t* elemPos)
{
    assert(list);
    assert(elemPos);

    size_t pos = list->end;

    do
    {
        const char* listKey = list->data[pos].value.key;
        
        if (listKey && AsmStrcmp(listKey, key))
        {
            *elemPos = pos;

            return HtListErrors::NO_ERR;
        }
        
        pos = list->data[pos].next;
    } while (pos != list->end);
    
    return HtListErrors::NO_ELEMENT_FOUND;
}
```

Для понимания кода также необходимо взглянуть на структуры, используемые в программе:

```
struct HashTableElemType
{
    char* key;

    bool val;
};

struct HtListElemType
{
    HashTableElemType value;

    size_t prevPos;
    size_t nextPos;
};

struct HtListType
{
    HtListElemType* data;

    size_t end;
    size_t freeBlockHead;

    size_t size;
    size_t capacity;
};

enum class HtListErrors
{
    NO_ERR,

    MEMORY_ERR,

    DATA_IS_NULLPTR,
    OUT_OF_RANGE,

    INVALID_NULLPTR,
    INVALID_DATA,

    TRYING_TO_GET_NULL_ELEMENT,
    TRYING_TO_CHANGE_NULL_ELEMENT,

    NO_ELEMENT_FOUND,
};
```

Посмотрим, во что это компилируется:

```
HtListFindElemByKey(HtListType*, char const*, unsigned long*):
        mov     r9, QWORD PTR [rdi+8]       ; в r9 записывается list end
        mov     r10, QWORD PTR [rdi]        ; в r10 list data
        xor     r11d, r11d                  ; r11d обнуляется
        mov     rcx, r9                     ; в rcx list end
.L4:
        mov     rax, rcx                    ; в rax пишется pos
        sal     rax, 5                      ; домножение на 32, как sizeof(HtListElemType)
        add     rax, r10                    ; сдвиг относительно list->data
        mov     r8, QWORD PTR [rax]         ; в r8 кладется элемент list->data[pos].value.key 
        test    r8, r8                      ; 
        je      .L2                         ; jump if r8 == nullptr
        mov     edi, r11d                   ; edi = 0

        .intel_syntax noprefix          ; \
        vmovdqu ymm0, YMMWORD PTR [r8]  ; |
        vptest ymm0,  YMMWORD PTR [rsi] ; Asm strcmp inlined
        setc dil                        ; |
        vzeroupper                      ;/

        test    edi, edi                ; проверить asm strcmp res 
        jne     .L13                    ; если asm strcmp res != 0 -> jmp L13
.L2:
        mov     rcx, QWORD PTR [rax+24]     ; rcx = list->data[pos].nextPos
        cmp     r9, rcx                     ; сравнивается rcx и list->end
        jne     .L4                         ; цикл если rcx != list->end
        mov     eax, 8                      ; return NO_ELEMENT_FOUND
        ret
.L13:
        mov     QWORD PTR [rdx], rcx        ; загрузить в *elemPos ответ 
        xor     eax, eax                    ; return NO_ERR
        ret 
```

Заметим возможные оптимизации:
1. В моем коде list->end это всегда 0, то есть вместо обращения к памяти в начале, можно просто засеттить 0.
2. `vzeroupper` не нужно вызывать каждый раз, так как внутри одной этой функции нет перехода от AVX к SSE инструкциям - сделаем один вызов перед ретерном.
3. Строчка `vptest ymm0, YMMWORD PTR [rsi]` каждый раз обращается к памяти, по которой расположен key, когда, на самом деле, можно выгрузить его в регистр ymm0, а обращаться к памяти в хештаблице, так как key не изменен, а по памяти в хештаблице мы двигаемся. Также, нет никакого смысла делать `setc dil`, а затем `test edi, edi`, так как `vptest` уже устанавливает CARRY FLAG в случае, если две строчки равны. 

Перепишем с применением наших оптимизаций:

```
HtListFindElemByKey:    ; (HtListType* list, const char* key, size_t* elemPos)
        mov     r9, QWORD  [rdi]        ; r9 = list->data
        xor     ecx, ecx                ; ecx = 0 (стартовая позиция)
        xor     r10d, r10d              ; r10d = 0

        vmovdqu ymm0, YWORD  [rsi]    ; loading key to ymm0
DO_WHILE_BODY:
        mov     rax, rcx                ; rax = pos
        sal     rax, 5                  ; rax * sizeof(HtListElemType)
        add     rax, r9                 ; rax = list->data + pos
        mov     r8, QWORD  [rax]        ; r8  = list->data[pos].value.key
        test    r8, r8                  ;
        je      DO_WHILE_CONDITION      ; if r8 == null jmp to condition
        
        vptest ymm0, YWORD  [r8]      ;
        jc HT_LIST_RET                  ; compare r8 and key. If equal -> ret

DO_WHILE_CONDITION:
        mov     rcx, QWORD  [rax+24]    ; rcx = list->data[pos].nextPos
        test    rcx, rcx                ;
        jne     DO_WHILE_BODY           ; if rcx != 0 -> continue
        mov     eax, 8                  ; return NO_ELEMENT_FOUND

        vzeroupper
        ret

HT_LIST_RET:
        mov     QWORD  [rdx], rcx       ; *elemPos = pos
        xor     eax, eax                ; return NO_ERR

        vzeroupper
        ret
```

Данный код написан в [отедельном файле](/Src/HashTable/HashTableList/HashTableListAsm.s) на ассемблере и линкуется с моей программой. 

Измерения:

|                            |Запуск 1     |Запуск 2     |Запуск 3      | Среднее по мнк           |
|---                         |---          |---          |---           |---                       |
|list find elem asm          | 18265832736 | 18743839108 | 17652099914  | $(182 \pm 6) \cdot 10^8$ |

Характерное время работы программы - около 10 секунд. 

|                     |Абсолютное ускорение |Относительное ускорение|
|---                  |---                  |---                    |
|Наивная реализация   | 1                   |  1                    |
|Intrinsic CRC32      | $1.80 \pm 0.08$     | $1.80 \pm 0.08$       |
|Strcmp inlined asm   | $2.50 \pm 0.16$     | $1.39 \pm 0.11$       |
|list find elem asm   | $2.79 \pm 0.14$     | $1.12 \pm 0.09$       |

Видно, что последняя оптимизация хоть и дала какой-то прирост производительности, но, фактически, сильно затруднила понимание кода, так как была написана целая функция на ассемблере. Отказываться от этой оптимизации или нет - зависит от требований к программе. Если выигрыш в $1.12$ раз сильно необходим, то оптимизацию следует оставить. Если острой необходимости в этом нет, то следует от нее отказаться, так как она сильно влияет на читабельность кода, но при этом не дает существенного повышения производительности. Так как эта оптимизация уже не дает заметного выигрыша в производительности, анализировать и искать узкие места дальше не имеет смысла, остановимся на этом.

## Оптимизация размера таблицы

Несмотря на то, что размер таблицы для данного задания был зафиксирован так, чтобы load-factor был 7.5, не стоит забывать, что в реальных хештаблицах чаще всего используется load-factor около 0.7. Давайте измерим время работы хештаблицы при увеличенном ее размере. В этот раз размер будет $n = 528001$. Тогда $loadFactor = 0.70$. 

Измерения:

|                            |Запуск 1     |Запуск 2     |Запуск 3      | Среднее по мнк           |
|---                         |---          |---          |---           |---                       |
|load-factor 0.7             | 12736916412 | 12519980688 | 13195608752  | $(128 \pm 3) \cdot 10^8$ |

Характерное время работы программы - около 7 секунд. 

## Сводка

Сводная таблица результатов:

|                     |Абсолютное ускорение |Относительное ускорение|Время в тактах             |
|---                  |---                  |---                    |---                        | 
|Наивная реализация   | 1                   |  1                    | $(508 \pm 8) \cdot 10^8$  | 
|Intrinsic CRC32      | $1.80 \pm 0.08$     | $1.80 \pm 0.08$       | $(282 \pm 8) \cdot 10^8$  |
|Strcmp inlined asm   | $2.50 \pm 0.16$     | $1.39 \pm 0.11$       | $(203 \pm 10) \cdot 10^8$ |
|list find elem asm   | $2.79 \pm 0.14$     | $1.12 \pm 0.09$       | $(182 \pm 6) \cdot 10^8$  |
|load-factor 0.7      | $3.97 \pm 0.16$     | $1.42 \pm 0.08$       | $(128 \pm 3) \cdot 10^8$  |

Получается, оптимальный выбор load-factor'a может значительно улушчить скорость работы программы. 

Посчитаем коэффициент $balance$ по формуле:

$$balance = \frac{\frac{T}{T_0}}{NumberOfOptimizingCodeLines} \cdot 1000$$

Посчитаем это для случаев Strcmp inlined asm и list find elem asm. Для случая с уменьшением load-factor'а считать не будем, так как фактически эта оптимизация никак не затрагивала ассемблерные инструкции. 

Посчитаем количество строчек кода, написанных для оптимизации. В каждой ячейке учитывается число строчек, написанных для предыдущих оптимизаций + для этой оптимизации.

|                     |NumberOfOptimizingCodeLines |
|---                  |---                         |
|Наивная реализация   | 0                          |
|Intrinsic CRC32      | 4                          |
|Strcmp inlined asm   | 10                         |
|list find elem asm   | 30                         |

Strcmp inlined asm:

$$balance = 250$$

List find elem asm:

$$balance = 93$$

Хоть коэффициент и довольно странный, но все-таки отображает то, насколько хорош баланс между ухудшением читабельности и поддерживаемости кода и полученным выигрышем в производительности. И по нему можно опять сделать вывод, что оптимизация list find elem asm не является критически важной и от нее можно отказаться.

## Выводы

Программу стоит оптимизировать тогда, когда она уже точно идеально отлажена, но при этом остро необходима большая производительность. Оптимизации с использованием intrinsic-ов, ассмеблерных вставок и тому подобных сопряжены с ухудшение поддерживаемость и читабельности кода. Также, такой код сложно переносим, так как может быть завязан под конкретную архитектуру. 

Прежде чем приступать к оптимизации, нужно проверить, насколько хорошо реализован сам алгоритм. В данном случае перегруженность load-factor'а сильно влияла на производительность программы. После этого необходимо оценить самые узкие места в программе, чтобы понимать, что необходимо оптимизировать в первую очередь. Без подобного поиска узких мест, можно начать оптимизировать то, что почти не влияет на производительность, потратить кучу времени, испортить код, но при этом получить около-нулевой выхлоп. От некоторых уже сделанных оптимизаций стоит отказаться в пользу поддерживаемости и переносимости кода, если они не особо улучшают производительность программы. 

Ассемблерные оптимизации мощный инструмент - применяя только их, я смог добиться улучшения производительности программы в $2.79$ раз! Но все еще стоит несколько раз подумать, какую оптимизацию оставлять, а какую нет, и нужны ли вообще оптимизации в данный момент. 
